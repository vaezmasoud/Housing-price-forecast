{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1YtCEJS-uB5SgSBKREgR6rqjxTi3FnVqq","authorship_tag":"ABX9TyNJbZ6uZ1XOBu6qyO3e7S9Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Housing price forecast\n","In this project, we want to predict housing prices with the help of data. This dataset is downloaded from the Kaggel website and contains two datasets, train dataset and test dataset.\n","\n","https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data\n","\n","##import library and load data\n","In this section, we load the required datasets and view their basic information, including the number and name of columns, data type, etc."],"metadata":{"id":"HHXV-323iQiS"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"p3rR0qDdI3b4"},"outputs":[],"source":["import pandas as pd\n","train_data = pd.read_csv('/content/drive/MyDrive/ml/Housing-price-forecast/train.csv')\n","test_data = pd.read_csv('/content/drive/MyDrive/ml/Housing-price-forecast/test.csv')\n"]},{"cell_type":"code","source":["print(train_data.head())\n","print(train_data.info())\n","print(train_data.describe())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EjBwAtvFjYUq","executionInfo":{"status":"ok","timestamp":1703568952709,"user_tz":-210,"elapsed":437,"user":{"displayName":"Masoud Gaming","userId":"01529317132170938105"}},"outputId":"d9dfa638-ff3a-47dd-eb45-d6e1cf56691d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n","0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n","1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n","2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n","3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n","4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n","\n","  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n","0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n","1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n","2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n","3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n","4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n","\n","  YrSold  SaleType  SaleCondition  SalePrice  \n","0   2008        WD         Normal     208500  \n","1   2007        WD         Normal     181500  \n","2   2008        WD         Normal     223500  \n","3   2006        WD        Abnorml     140000  \n","4   2008        WD         Normal     250000  \n","\n","[5 rows x 81 columns]\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1460 entries, 0 to 1459\n","Data columns (total 81 columns):\n"," #   Column         Non-Null Count  Dtype  \n","---  ------         --------------  -----  \n"," 0   Id             1460 non-null   int64  \n"," 1   MSSubClass     1460 non-null   int64  \n"," 2   MSZoning       1460 non-null   object \n"," 3   LotFrontage    1201 non-null   float64\n"," 4   LotArea        1460 non-null   int64  \n"," 5   Street         1460 non-null   object \n"," 6   Alley          91 non-null     object \n"," 7   LotShape       1460 non-null   object \n"," 8   LandContour    1460 non-null   object \n"," 9   Utilities      1460 non-null   object \n"," 10  LotConfig      1460 non-null   object \n"," 11  LandSlope      1460 non-null   object \n"," 12  Neighborhood   1460 non-null   object \n"," 13  Condition1     1460 non-null   object \n"," 14  Condition2     1460 non-null   object \n"," 15  BldgType       1460 non-null   object \n"," 16  HouseStyle     1460 non-null   object \n"," 17  OverallQual    1460 non-null   int64  \n"," 18  OverallCond    1460 non-null   int64  \n"," 19  YearBuilt      1460 non-null   int64  \n"," 20  YearRemodAdd   1460 non-null   int64  \n"," 21  RoofStyle      1460 non-null   object \n"," 22  RoofMatl       1460 non-null   object \n"," 23  Exterior1st    1460 non-null   object \n"," 24  Exterior2nd    1460 non-null   object \n"," 25  MasVnrType     1452 non-null   object \n"," 26  MasVnrArea     1452 non-null   float64\n"," 27  ExterQual      1460 non-null   object \n"," 28  ExterCond      1460 non-null   object \n"," 29  Foundation     1460 non-null   object \n"," 30  BsmtQual       1423 non-null   object \n"," 31  BsmtCond       1423 non-null   object \n"," 32  BsmtExposure   1422 non-null   object \n"," 33  BsmtFinType1   1423 non-null   object \n"," 34  BsmtFinSF1     1460 non-null   int64  \n"," 35  BsmtFinType2   1422 non-null   object \n"," 36  BsmtFinSF2     1460 non-null   int64  \n"," 37  BsmtUnfSF      1460 non-null   int64  \n"," 38  TotalBsmtSF    1460 non-null   int64  \n"," 39  Heating        1460 non-null   object \n"," 40  HeatingQC      1460 non-null   object \n"," 41  CentralAir     1460 non-null   object \n"," 42  Electrical     1459 non-null   object \n"," 43  1stFlrSF       1460 non-null   int64  \n"," 44  2ndFlrSF       1460 non-null   int64  \n"," 45  LowQualFinSF   1460 non-null   int64  \n"," 46  GrLivArea      1460 non-null   int64  \n"," 47  BsmtFullBath   1460 non-null   int64  \n"," 48  BsmtHalfBath   1460 non-null   int64  \n"," 49  FullBath       1460 non-null   int64  \n"," 50  HalfBath       1460 non-null   int64  \n"," 51  BedroomAbvGr   1460 non-null   int64  \n"," 52  KitchenAbvGr   1460 non-null   int64  \n"," 53  KitchenQual    1460 non-null   object \n"," 54  TotRmsAbvGrd   1460 non-null   int64  \n"," 55  Functional     1460 non-null   object \n"," 56  Fireplaces     1460 non-null   int64  \n"," 57  FireplaceQu    770 non-null    object \n"," 58  GarageType     1379 non-null   object \n"," 59  GarageYrBlt    1379 non-null   float64\n"," 60  GarageFinish   1379 non-null   object \n"," 61  GarageCars     1460 non-null   int64  \n"," 62  GarageArea     1460 non-null   int64  \n"," 63  GarageQual     1379 non-null   object \n"," 64  GarageCond     1379 non-null   object \n"," 65  PavedDrive     1460 non-null   object \n"," 66  WoodDeckSF     1460 non-null   int64  \n"," 67  OpenPorchSF    1460 non-null   int64  \n"," 68  EnclosedPorch  1460 non-null   int64  \n"," 69  3SsnPorch      1460 non-null   int64  \n"," 70  ScreenPorch    1460 non-null   int64  \n"," 71  PoolArea       1460 non-null   int64  \n"," 72  PoolQC         7 non-null      object \n"," 73  Fence          281 non-null    object \n"," 74  MiscFeature    54 non-null     object \n"," 75  MiscVal        1460 non-null   int64  \n"," 76  MoSold         1460 non-null   int64  \n"," 77  YrSold         1460 non-null   int64  \n"," 78  SaleType       1460 non-null   object \n"," 79  SaleCondition  1460 non-null   object \n"," 80  SalePrice      1460 non-null   int64  \n","dtypes: float64(3), int64(35), object(43)\n","memory usage: 924.0+ KB\n","None\n","                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n","count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n","mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n","std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n","min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n","25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n","50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n","75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n","max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n","\n","       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n","count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n","mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n","std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n","min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n","25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n","50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n","75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n","max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n","\n","        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n","count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n","mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n","std     125.338794    66.256028      61.119149    29.317331    55.757415   \n","min       0.000000     0.000000       0.000000     0.000000     0.000000   \n","25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n","50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n","75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n","max     857.000000   547.000000     552.000000   508.000000   480.000000   \n","\n","          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n","count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n","mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n","std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n","min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n","25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n","50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n","75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n","max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n","\n","[8 rows x 38 columns]\n"]}]},{"cell_type":"code","source":["print(test_data.head())\n","print(test_data.info())\n","print(test_data.describe())"],"metadata":{"id":"q92Z-y6ikUa6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##data prepare\n","At this stage, we select the features that we intend to use to predict the housing price. If we have a non-numeric data type, we convert them to numeric data and complete the incomplete data.\n","\n","###feature selection\n","\n","Choosing the optimal features is one of the critical steps in the success of a prediction model. Choosing the right features can improve model performance, reduce training and prediction time, and avoid overfitting. In the following, I will explain the different methods of selecting features:\n","\n","Analysis of the impact and importance of features:\n","You can see the effect of each feature on the output of the model from methods such as Feature Importance analysis, which is used by decision trees and warehouse-based algorithms, including Random Forest.\n","\n","Dimension reduction:\n","Use dimensionality reduction techniques such as principal component analysis (PCA). These methods help you reduce the number of features and retain important information.\n","\n","Using methods related to the model:\n","Some machine learning algorithms such as LASSO (Least Absolute Shrinkage and Selection Operator) and Ridge Regression use techniques to avoid overfitting by reducing unnecessary features.\n","\n","Selection of evaluation criteria:\n","Evaluation criteria can help you select features that perform better based on their effectiveness on the evaluation criteria.\n","\n","Thematic search algorithms:\n","Algorithms such as genetic algorithm and thematic search algorithms (such as Recursive Feature Elimination) can help you find the optimal set of features.\n","\n","Correlation analysis:\n","Check the correlation between features and if there are features that are correlated, you can remove one of them.\n","\n","Using special feature selection methods:\n","Some special feature selection methods such as Recursive Feature Elimination (RFE) and SelectKBest use feature selection modules in Scikit-learn.\n","\n","Remember that feature selection should be done carefully and consider its detrimental effects on model performance. Also, it is always important to carefully evaluate the effects of feature selection on the final model.\n","\n","###fill NaN cells and convert data types\n","\n","We filled the empty and incomplete values of the dataset in the selected features with the help of the average and with the help of the \"fillna()\" function.\n","\n","\n","Because some of the selected features are of non-numeric data type, in order to be able to include them in the model, we first need to convert these features to numeric data type. Here we used the \"One-Hot Encoding\" method. In this method, we call a function named \"get_dummies\" from the Pendaz library and give the selected features to this function. In this function, in order for the number of new columns to match the rows, we have considered the value \"drop_first=True\"."],"metadata":{"id":"roQ64xv1jx8K"}},{"cell_type":"code","source":["# select features and depend variable (target)\n","features = train_data[['MSZoning', 'LotFrontage','LandContour', 'BldgType', 'YearBuilt', 'RoofStyle', 'Exterior1st', 'Foundation', 'YrSold', 'SaleType', 'SaleCondition']]\n","target = train_data['SalePrice']\n","\n","# fill NaN variables with mean\n","features.fillna(features.mean(), inplace=True)\n","\n","# convert features to numeric\n","features_encoded = pd.get_dummies(features, drop_first=True)\n","\n","# add new columns to features\n","features = pd.concat([features, features_encoded], axis=1)\n","\n","# remove main features that converted to One-Hot Encoding\n","features = features.drop(['MSZoning', 'LandContour', 'BldgType', 'RoofStyle', 'Exterior1st', 'Foundation', 'SaleType', 'SaleCondition'], axis=1)\n","\n","# dividing dataset to train data and test data\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fiXqbL2pjulh","executionInfo":{"status":"ok","timestamp":1703581112632,"user_tz":-210,"elapsed":438,"user":{"displayName":"Masoud Gaming","userId":"01529317132170938105"}},"outputId":"cdceb343-80e7-44e3-c710-34513166f9a9"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-10-b9ffd15f7e5c>:6: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n","  features.fillna(features.mean(), inplace=True)\n","<ipython-input-10-b9ffd15f7e5c>:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  features.fillna(features.mean(), inplace=True)\n"]}]},{"cell_type":"markdown","source":["##Select Features with RandomForest (Optional)"],"metadata":{"id":"qJPScI2jVZSp"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.feature_selection import SelectFromModel\n","from sklearn.model_selection import train_test_split\n","\n","# ساخت یک مدل Random Forest\n","model_selection_feature = RandomForestRegressor()\n","\n","all_features = train_data[['MSSubClass','MSZoning','LotFrontage','LotArea','Street','Alley','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood','Condition1','Condition2','BldgType','HouseStyle','OverallQual','OverallCond','YearBuilt','YearRemodAdd','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','MasVnrArea','ExterQual','ExterCond','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinSF1','BsmtFinType2','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','Heating','HeatingQC','CentralAir','Electrical','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','KitchenQual','TotRmsAbvGrd','Functional','Fireplaces','FireplaceQu','GarageType','GarageYrBlt','GarageFinish','GarageCars','GarageArea','GarageQual','GarageCond','PavedDrive','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','PoolQC','Fence','MiscFeature','MiscVal','MoSold','YrSold','SaleType','SaleCondition']]\n","target = train_data['SalePrice']\n","\n","# fill NaN variables with mean\n","all_features.fillna(all_features.mean(), inplace=True)\n","\n","# convert features to numeric\n","features_encoded = pd.get_dummies(all_features, drop_first=True)\n","\n","# add new columns to features\n","all_features = pd.concat([all_features, features_encoded], axis=1)\n","\n","# remove main features that converted to One-Hot Encoding\n","all_features = all_features.drop(['MSSubClass','MSZoning','LotFrontage','LotArea','Street','Alley','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood','Condition1','Condition2','BldgType','HouseStyle','OverallQual','OverallCond','YearBuilt','YearRemodAdd','RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','MasVnrArea','ExterQual','ExterCond','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinSF1','BsmtFinType2','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF','Heating','HeatingQC','CentralAir','Electrical','1stFlrSF','2ndFlrSF','LowQualFinSF','GrLivArea','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','KitchenQual','TotRmsAbvGrd','Functional','Fireplaces','FireplaceQu','GarageType','GarageYrBlt','GarageFinish','GarageCars','GarageArea','GarageQual','GarageCond','PavedDrive','WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','PoolArea','PoolQC','Fence','MiscFeature','MiscVal','MoSold','YrSold','SaleType','SaleCondition'], axis=1)\n","\n","X_train, X_test, y_train, y_test = train_test_split(all_features, target, test_size=0.2, random_state=42)\n","\n","# آموزش مدل بر روی داده‌ها\n","model_selection_feature.fit(X_train, y_train)\n","\n","# ایجاد یک مدل انتخاب ویژگی بر اساس اهمیت ویژگی‌ها\n","sfm = SelectFromModel(model_selection_feature, threshold=0.1)\n","\n","# اعمال مدل انتخاب ویژگی بر روی داده‌های آموزشی\n","sfm.fit(X_train, y_train)\n","\n","# انتخاب ویژگی‌ها\n","selected_features = X_train.columns[sfm.get_support()]\n"],"metadata":{"id":"ghtkjOpE34UZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(selected_features)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q1JEwraXUqz1","executionInfo":{"status":"ok","timestamp":1703580718671,"user_tz":-210,"elapsed":499,"user":{"displayName":"Masoud Gaming","userId":"01529317132170938105"}},"outputId":"6c190017-8600-49e4-e746-818ca6336007"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['ExterQual_TA'], dtype='object')\n"]}]},{"cell_type":"markdown","source":["##Create Model\n","\n","**with RandomForest algorithm**\n","\n","The RandomForest algorithm is a machine learning algorithm based on ensemble ideas that uses the combination of several decision trees to improve performance and prediction accuracy. Below is a description of the RandomForest algorithm:\n","\n","Decision Tree: A decision tree is a machine learning model that is built by dividing data into smaller parts (areas) and applying a decision to each area.\n","A decision tree results in a tree-like structure with branches and nodes.\n","\n","Ensemble: RandomForest uses the idea of ensemble. Instead of using one decision tree as the main model, it uses multiple decision trees as groups. Each decision tree is trained independently and makes decisions.\n","\n","Random Feature Selection: In each node of each tree, only a limited number of features are considered for data division. This random selection of features helps to diversify and prevent overfitting.\n","\n","Combining Predictions: The final prediction is made by combining the predictions of each decision tree. A final forecast is usually produced by applying a majority decision or averaging the forecasts.\n","\n","Adjustable parameters: In the RandomForest algorithm, the number of trees (n_estimators), the number of features for each partition (max_features) and the depth level of the trees (max_depth) are adjustable parameters.\n","\n","Application in housing price forecasting: RandomForest performs well in housing price forecasting problems. Due to its ability to control over-discrepancy and prevent over-fitting to the training data, this algorithm is usually successful in prediction tasks.\n","The RandomForest algorithm is usually used to predict housing prices due to its ability to handle high-dimensional data and the complexity of issues related to the housing market."],"metadata":{"id":"aT9NERAWuLR_"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\n","model = RandomForestRegressor(n_estimators=100, random_state=42)"],"metadata":{"id":"WAeyRPDeuNnX","executionInfo":{"status":"ok","timestamp":1703581121981,"user_tz":-210,"elapsed":359,"user":{"displayName":"Masoud Gaming","userId":"01529317132170938105"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["##train model"],"metadata":{"id":"iZ94Xcd3uP-W"}},{"cell_type":"code","source":["model.fit(X_train, y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":75},"id":"XppOAE3PuSRn","executionInfo":{"status":"ok","timestamp":1703581127765,"user_tz":-210,"elapsed":1763,"user":{"displayName":"Masoud Gaming","userId":"01529317132170938105"}},"outputId":"e7f71b53-8696-4a38-e6e4-08efab3c1812"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestRegressor(random_state=42)"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(random_state=42)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["##Evaluation model\n","\n","In the model evaluation stage, various criteria are used to quantitatively evaluate the performance of the model. In the housing price prediction project, various criteria can be used to evaluate the model. One of the common criteria for regression prediction problems is the MSE (Mean Squared Error) criterion. MSE is one of the most common evaluation criteria for regression problems and measures the root mean square difference between the model predictions and the actual values.\n","\n","1. Can AUC and ROC be calculated for housing price forecasting project?\n","\n","AUC (Area Under the Curve) and ROC (Receiver Operating Characteristic) are terms used as evaluation criteria in classification problems. These criteria are usually used in cases where the number of positive and negative samples is different, such as disease diagnosis problems or problems related to the medical field.\n","\n","In a house price forecasting project that is modeled as a regression problem (numerical value forecasting), classification measures such as AUC and ROC are usually not used. These criteria are used to evaluate a model's ability to separate positive and negative classes based on estimated probabilities."],"metadata":{"id":"fLxFCWi5uV9J"}},{"cell_type":"code","source":["from sklearn.metrics import mean_squared_error\n","\n","predictions = model.predict(X_test)\n","mse = mean_squared_error(y_test, predictions)\n","print(f'Mean Squared Error: {mse}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZ94jaMHuU6P","executionInfo":{"status":"ok","timestamp":1703581134332,"user_tz":-210,"elapsed":348,"user":{"displayName":"Masoud Gaming","userId":"01529317132170938105"}},"outputId":"977ce237-5a52-47e2-8c11-ca9554a68853"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 3794358217.654185\n"]}]},{"cell_type":"markdown","source":["##Prediction Model"],"metadata":{"id":"sq2THbtQzO8B"}},{"cell_type":"code","source":["import pandas as pd\n","\n","# new data for predict price\n","new_data = pd.DataFrame({\n","    'MSZoning': [\"RH\"],\n","    'LotFrontage': [117],\n","    'LandContour': [\"Lvl\"],\n","    'BldgType': [\"1Fam\"],\n","    'YearBuilt': [2003],\n","    'RoofStyle': [\"Gable\"],\n","    'Exterior1st': [\"VinylSd\"],\n","    'Foundation': [\"CBlock\"],\n","    'YrSold': [2010],\n","    'SaleType': [\"WD\"],\n","    'SaleCondition': [\"Normal\"]\n","})\n","\n","# convert categorials data in new data to On-Hot Encoding\n","new_data_encoded = pd.get_dummies(new_data, drop_first=True)\n","\n","# Homogenization new data columns with train data columns\n","new_data_encoded_aligned = new_data_encoded.reindex(columns=X_train.columns, fill_value=0)\n","\n","# predicting with Basic model\n","predicted_price = model.predict(new_data_encoded_aligned)\n","print(f'Predicted Price: {predicted_price[0]}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M75E9bKkzRTf","executionInfo":{"status":"ok","timestamp":1703581347388,"user_tz":-210,"elapsed":773,"user":{"displayName":"Masoud Gaming","userId":"01529317132170938105"}},"outputId":"6d28fc5d-4ee5-485b-804a-e59bc6e83bb5"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Price: 296501.05\n"]}]},{"cell_type":"markdown","source":["##optimization Model (Optional)\n","The model optimization stage is an important stage in building and adjusting a machine learning model. Methods such as GridSearchCV and RandomizedSearchCV are used to optimally adjust the parameters of the model. These methods allow you to search a space of parameters and choose the best values for your model.\n","\n","1. Grid Search:\n","In GridSearchCV, you provide a set of possible values for each parameter and the algorithm tries all possible combinations. This method is the most time-consuming, but it finds the best parameters.\n","\n","2. Randomized Search:\n","In RandomizedSearchCV, instead of trying all combinations, a certain number of combinations are randomly selected. This method is more practical for larger or time-consuming parameter spaces."],"metadata":{"id":"U-o1vdLzvSa4"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","\n","# The model used\n","model = RandomForestRegressor()\n","\n","#Parameters space\n","param_grid = {\n","    'n_estimators': [10, 50, 100, 200],\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","\n","# Create a GridSearchCV with model, parameter space and number of partitions\n","grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n","\n","# Training the model on the training data\n","grid_search.fit(X_train, y_train)\n","\n","# Best parameters and relevant results\n","best_params = grid_search.best_params_\n","best_score = grid_search.best_score_\n","\n","print(f'Best Parameters: {best_params}')\n","print(f'Best Score: {best_score}')"],"metadata":{"id":"CY3Lp4agvVDo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import RandomizedSearchCV\n","from scipy.stats import randint\n","\n","# The model used\n","model = RandomForestRegressor()\n","\n","#Parameters space\n","param_dist = {\n","    'n_estimators': randint(10, 200),\n","    'max_depth': [None, 10, 20, 30],\n","    'min_samples_split': randint(2, 10),\n","    'min_samples_leaf': randint(1, 4)\n","}\n","\n","#Create a RandomizedSearchCV with model, parameter space and number of partitions\n","random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=10, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)\n","\n","#Training the model on the training data\n","random_search.fit(X_train, y_train)\n","\n","#Best parameters and relevant results\n","best_params = random_search.best_params_\n","best_score = random_search.best_score_\n","\n","print(f'Best Parameters: {best_params}')\n","print(f'Best Score: {best_score}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BD_R4ZJzwVCM","executionInfo":{"status":"ok","timestamp":1703581634139,"user_tz":-210,"elapsed":32123,"user":{"displayName":"Masoud Gaming","userId":"01529317132170938105"}},"outputId":"67c23179-35a9-4240-b691-17c46ec31f6b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Parameters: {'max_depth': 30, 'min_samples_leaf': 3, 'min_samples_split': 7, 'n_estimators': 199}\n","Best Score: -2916148236.956235\n"]}]},{"cell_type":"code","source":["#evaluation random_search model\n","from sklearn.metrics import mean_squared_error\n","\n","predictions = random_search.predict(X_test)\n","mse = mean_squared_error(y_test, predictions)\n","print(f'Mean Squared Error: {mse}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JPfy8kBUxnxT","executionInfo":{"status":"ok","timestamp":1703504447346,"user_tz":-210,"elapsed":9,"user":{"displayName":"Masoud Gaming","userId":"01529317132170938105"}},"outputId":"1a87142a-3b1b-4a0a-fa15-7592a9542c78"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error: 3408387808.1307755\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# new data for predict price\n","new_data = pd.DataFrame({\n","    'MSZoning': [\"RH\"],\n","    'LotFrontage': [117],\n","    'LandContour': [\"Lvl\"],\n","    'BldgType': [\"1Fam\"],\n","    'YearBuilt': [2003],\n","    'RoofStyle': [\"Gable\"],\n","    'Exterior1st': [\"VinylSd\"],\n","    'Foundation': [\"CBlock\"],\n","    'YrSold': [2010],\n","    'SaleType': [\"WD\"],\n","    'SaleCondition': [\"Normal\"]\n","})\n","\n","# convert categorials data in new data to On-Hot Encoding\n","new_data_encoded = pd.get_dummies(new_data, drop_first=True)\n","\n","# Homogenization new data columns with train data columns\n","new_data_encoded_aligned = new_data_encoded.reindex(columns=X_train.columns, fill_value=0)\n","\n","# predicting with Basic model\n","predicted_price = random_search.predict(new_data_encoded_aligned)\n","print(f'Predicted Price: {predicted_price[0]}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i6rmmAZpYULR","executionInfo":{"status":"ok","timestamp":1703581698553,"user_tz":-210,"elapsed":340,"user":{"displayName":"Masoud Gaming","userId":"01529317132170938105"}},"outputId":"a0010d86-75c4-4cae-fa14-343a19d3d922"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted Price: 297306.3156426348\n"]}]},{"cell_type":"markdown","source":["##Feature Engineering (Optional)\n","\n","Feature engineering is an important process in data analysis and building predictive models, which involves transforming and creating new features based on existing data. In the housing price prediction project, you can create more useful and high-quality information for the model and improve its performance by performing feature engineering. Below are some ideas for doing feature engineering in this project:\n","\n","Convert attributes to a suitable format: You may want to convert the home's construction date into a useful attribute, for example, calculate the age of the home and add it as a new attribute.\n","If the data contains spatial information (such as latitude and longitude), you can create new spatial features.\n","\n","Extracting information from variables: If you have a feature such as LotArea, you can separately calculate the area of the house (internal) and the area of the yard and add it as a new feature. You can extract information from other features, such as the number of rooms and bathrooms, and add it as a new feature.\n","\n","Apply mathematical transformations: You can transform features, such as taking the logarithm of features whose distribution is heterogeneous. If the distribution of a feature is close to a normal distribution, it may be improved by statistical transformations such as standardization (a subset of feature scaling).\n","\n","Use subject knowledge: If you have specific knowledge in the field of real estate pricing, you can add features related to this knowledge. For example, topographic distances, distance to guest houses or urban service centers may be useful to add to the accuracy of the model.\n","\n","Consider corrective measures: If the data has unusual or defamatory values, you may want to apply corrective measures. For example, removing outliers or setting default values for incomplete data.\n","\n","Working with time features: If the data includes sales time, you might use information related to seasons or time changes as new features.\n","In either case, it's important to note that the changes you make will not only improve the information, but also make your model more capable of detecting hidden and more complex patterns in the data. For each change, it is critical to test and evaluate the performance of the model with these changes as well."],"metadata":{"id":"hu3omY9TzMgA"}}]}